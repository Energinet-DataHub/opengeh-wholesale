# Copyright 2020 Energinet DataHub A/S
#
# Licensed under the Apache License, Version 2.0 (the "License2");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: CI Databricks

on:
  workflow_call: {}

jobs:
  databricks_ci_build:
    uses:  Energinet-DataHub/.github/.github/workflows/databricks-build-prerelease.yml@v10
    with:
      PYHTON_VERSION: '3.9.7'
      ARCHITECTURE: 'x64'
      WHEEL_WORKING_DIRECTORY: './source/databricks'

  migration_scripts_verification:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout current branch
        uses: actions/checkout@v2

      - name: Get file from current branch
        id: get_current_files
        run: |
          CURRENT_FILES=$(find ./source/databricks/package/datamigration/migration_scripts -type f -not -name '__*' -printf "%f," | sort -r)
          echo "::set-output name=current_files::$CURRENT_FILES"

      - name: Checkout main branch
        uses: actions/checkout@v2
        with:
          ref: main

      - name: Get file from main branch
        id: get_main_files
        run: |
          MAIN_FILES=$(find ./source/databricks/package/datamigration/migration_scripts -type f -not -name '__*' -printf "%f,")
          echo "::set-output name=main_files::$MAIN_FILES"

      - name: Compare file lists
        run: |
          DATETIME=$(TZ=Europe/Paris date +"%Y-%m-%d %H:%M:%S")
          IFS=','
          echo "-------------------current files-----------------------"
          CURRENT_FILES="${{ steps.get_current_files.outputs.current_files }}"
          echo "${CURRENT_FILES}"
          read -ra CURRENT_FILES_ARRAY <<<"$CURRENT_FILES"
          current_files_sorted_array=($(echo "${CURRENT_FILES_ARRAY[@]}" | tr ' ' '\n' | sort -r))
          for file in "${current_files_sorted_array[@]}"
          do
            echo "$file"
            CURRENT_FILE_DATE=$(date -d "${file:0:8} ${file:8:2}:${file:10:2}" +"%Y-%m-%d %H:%M:%S")
            if [[ $CURRENT_FILE_DATE > $DATETIME ]]; then
              echo "New migration file can not be later than current datetime"
              exit 1
            fi
          done
          echo "${CURRENT_FILES_ARRAY[0]}"

          echo "-------------------main files-----------------------"
          MAIN_FILES="${{ steps.get_main_files.outputs.main_files }}"
          read -ra MAIN_FILES_ARRAY <<<"$MAIN_FILES"
          main_files_sorted_array=($(echo "${MAIN_FILES_ARRAY[@]}" | tr ' ' '\n' | sort -r))
          for file in "${main_files_sorted_array[@]}"
          do
            echo "$file"
          done
          echo "test 1"
          echo "${main_files_sorted_array[0]}"
          echo "test 2"
          echo "${MAIN_FILES_ARRAY[0]}"
          echo "---------------------combined----------------------"
          unique_arr=()
          for item in "${CURRENT_FILES_ARRAY[@]}"
          do
            if [[ ! " ${MAIN_FILES_ARRAY[@]} " =~ "${item}" ]]; then
              unique_arr+=("$item")
            fi
          done
          echo "${unique_arr[@]}"

          # MAIN_FILE_DATE=$(date -d "${MAIN_FILE:0:8} ${MAIN_FILE:8:2}:${MAIN_FILE:10:2}" +"%Y-%m-%d %H:%M:%S")
          # echo $DATETIME
          # echo $CURRENT_FILE_DATE
          # echo $MAIN_FILE
          # echo $MAIN_FILE_DATE

          # if [[ $CURRENT_FILE_DATE > $DATETIME ]]; then
          #   echo "New migration file can not be later than current datetime"
          #   exit 1
          # fi

          # if [[ $CURRENT_FILE_DATE < $MAIN_FILE_DATE ]]; then
          #   echo "New migration file can not be before existing migration"
          #   exit 1
          # fi


  databricks_ci_test:
    uses: Energinet-DataHub/.github/.github/workflows/python-ci.yml@v10
    with:
      OPERATING_SYSTEM: 'dh3-ubuntu-20.04-4core'
      PATH_STATIC_CHECKS: './source/databricks'
      # documented here https://github.com/Energinet-DataHub/opengeh-wholesale/tree/main/source/databricks#styling-and-formatting
      IGNORE_ERRORS_AND_WARNING_FLAKE8: 'E501,F401,E402,E203,W503'
      TEST_REPORT_PATH: ./source/databricks/tests/htmlcov/

  mypy_check:
    runs-on: ubuntu-latest
    name: Static type checker
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v4
      with:
        python-version: 3.x
    - name: Run pip intall and mypy check of files in package
      shell: bash
      run: |
        pip install --upgrade pip
        pip install mypy types-python-dateutil
        mypy ./source/databricks/package --disallow-untyped-defs --ignore-missing-imports

  #
  # Branch policy status check
  #

  allow_merge:
    runs-on: ubuntu-latest
    needs: [
      databricks_ci_build,
      databricks_ci_test,
      mypy_check
    ]
    if: |
      always()
    steps:
      - name: Verify if merge is allowed
        run: |
          echo "${{ toJSON(needs) }}"

          if [[ ${{ contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled') }} = true ]]; then
              echo "Failed"
              exit 1
          fi
