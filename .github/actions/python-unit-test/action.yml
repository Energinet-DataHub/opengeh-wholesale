# Copyright 2020 Energinet DataHub A/S
#
# Licensed under the Apache License, Version 2.0 (the "License2");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: PySpark execution
description: This action allows you to execute code, written for Spark, Databricks or other similar engines.

runs:
  using: composite
  steps:
    # TODO: Mount .azure folder so token can be used from within docker
    - name: Execute entrypoint.sh (with retry)
      uses: nick-fields/retry@v2
      with:
        timeout_minutes: 15
        # Disabled retry after merge of PR-1048, as this retry might not be needed anymore.
        # Will keep it now, if pipeline is still unstable periodically, reverting will be much easier
        # Note: Dont forget to remove logic regarding exit codes in the entrypoint.sh script if removing retry logic at some point
        max_attempts: 1
        retry_on_exit_code: 2 # In our script we return exit code 2 if we detect a scenario for which to retry
        shell: bash
        command: |
          chmod +x ./.docker/entrypoint.sh
          docker-compose -f .devcontainer/docker-compose.yml run --rm -u root -w //workspaces/opengeh-wholesale wholesale ./.docker/entrypoint.sh
